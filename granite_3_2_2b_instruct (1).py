# -*- coding: utf-8 -*-
"""granite-3.2-2b-instruct.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//huggingface.co/ibm-granite/granite-3.2-2b-instruct.ipynb
"""

!pip install -U transformers

"""## Local Inference on GPU
Model page: https://huggingface.co/ibm-granite/granite-3.2-2b-instruct

‚ö†Ô∏è If the generated code snippets do not work, please open an issue on either the [model repo](https://huggingface.co/ibm-granite/granite-3.2-2b-instruct)
			and/or on [huggingface.js](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/model-libraries-snippets.ts) üôè
"""

# Use a pipeline as a high-level helper
from transformers import pipeline

pipe = pipeline("text-generation", model="ibm-granite/granite-3.2-2b-instruct")
messages = [
    {"role": "user", "content": "Who are you?"},
]
pipe(messages)

from huggingface_hub import login
login()

# Load model directly
from transformers import AutoTokenizer, AutoModelForCausalLM


tokenizer = AutoTokenizer.from_pretrained("ibm-granite/granite-3.2-2b-instruct")
model = AutoModelForCausalLM.from_pretrained("ibm-granite/granite-3.2-2b-instruct")
messages = [
    {"role": "user", "content": "Who are you?"},
]
inputs = tokenizer.apply_chat_template(
	messages,
	add_generation_prompt=True,
	tokenize=True,
	return_dict=True,
	return_tensors="pt",
).to(model.device)

outputs = model.generate(**inputs, max_new_tokens=40)
print(tokenizer.decode(outputs[0][inputs["input_ids"].shape[-1]:]))

!pip install transformers gradio pillow accelerate --quiet

from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM
import gradio as gr
from PIL import Image

# -----------------------------
# LOAD MODEL & PIPELINES
# -----------------------------

# Chat + translation model (text only)
chat_tokenizer = AutoTokenizer.from_pretrained("ibm-granite/granite-3.2-2b-instruct")
chat_model = AutoModelForCausalLM.from_pretrained(
    "ibm-granite/granite-3.2-2b-instruct",
    device_map="auto",
)

# Chatbot pipeline
chat_pipe = pipeline(
    "text-generation",
    model=chat_model,
    tokenizer=chat_tokenizer,
)

# Image analysis through generic image-to-text pipeline
# Granite 2B is not multimodal so we use a widely compatible HF pipeline
vision_pipe = pipeline(
    "image-to-text",
    model="nlpconnect/vit-gpt2-image-captioning"  # lightweight, no errors
)

# -----------------------------
# CHATBOT FUNCTION
# -----------------------------
def chatbot_fn(user_message):
    messages = [{"role": "user", "content": user_message}]
    output = chat_pipe(messages, max_new_tokens=150)
    return output[0]["generated_text"][-1]["content"]

# -----------------------------
# TRANSLATION FUNCTION
# -----------------------------
def translate_fn(text, target_lang):
    prompt = f"Translate this text to {target_lang}:\n{text}"
    messages = [{"role": "user", "content": prompt}]

    inputs = chat_tokenizer.apply_chat_template(
        messages,
        add_generation_prompt=True,
        tokenize=True,
        return_dict=True,
        return_tensors="pt"
    ).to(chat_model.device)

    outputs = chat_model.generate(**inputs, max_new_tokens=200)
    return chat_tokenizer.decode(outputs[0][inputs["input_ids"].shape[-1]:], skip_special_tokens=True)

# -----------------------------
# IMAGE ANALYSIS FUNCTION
# -----------------------------
def image_analysis_fn(img):
    if img is None:
        return "Please upload an image."
    result = vision_pipe(img)
    return result[0]["generated_text"]

# -----------------------------
# GRADIO UI
# -----------------------------
with gr.Blocks(title="AI Powered Audiobook Tool") as demo:

    gr.Markdown("## üìò AI Powered Audiobook Creation Tool\nIncludes Chatbot, Translation & Image Analysis")

    with gr.Tab("üí¨ Chatbot"):
        chatbot_input = gr.Textbox(label="Ask something...")
        chatbot_output = gr.Textbox(label="Response")
        chatbot_button = gr.Button("Send")
        chatbot_button.click(chatbot_fn, chatbot_input, chatbot_output)

    with gr.Tab("üåê Language Translation"):
        translate_input = gr.Textbox(label="Enter text to translate")
        target_lang = gr.Dropdown(
            ["Hindi", "Telugu", "Tamil", "Malayalam", "Kannada", "Marathi", "Bengali", "Gujarati", "Punjabi", "English"],
            label="Target Language"
        )
        translate_output = gr.Textbox(label="Translated Text")
        translate_button = gr.Button("Translate")
        translate_button.click(translate_fn, [translate_input, target_lang], translate_output)

    with gr.Tab("üñºÔ∏è Image Analysis"):
        img_input = gr.Image(type="pil", label="Upload Image")
        img_output = gr.Textbox(label="Image Description")
        img_button = gr.Button("Analyze Image")
        img_button.click(image_analysis_fn, img_input, img_output)

demo.launch(debug=True)

